{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "70b1be20",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import tensorflow as tf ## pip install tensorflow-gpu\n",
    "import cv2 ### pip install opencv-python\n",
    " ## pip install opencv-contrib-python  fullpackage\n",
    "import matplotlib.pyplot as plt ## pip install matplotlib\n",
    "import numpy as np ## pip install numpy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ebd29990",
   "metadata": {},
   "outputs": [],
   "source": [
    "Datadirectory = \"dataset\" ## training dataset\n",
    "Classes = [\"Closed_eyes\",\"Open_eyes\"] ## list of classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3134a74c",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_Data = []\n",
    "\n",
    "def create_training_Data():\n",
    "  for category in Classes:\n",
    "    path = os.path.join(Datadirectory, category)\n",
    "    class_num = Classes.index(category) ## 0 1,\n",
    "    for img in os.listdir(path):\n",
    "      try:\n",
    "          img_array = cv2.imread(os.path.join(path,img), cv2.IMREAD_GRAYSCALE)\n",
    "          backtorgb = cv2.cvtColor(img_array,cv2.COLOR_GRAY2RGB)\n",
    "          new_array = cv2.resize(backtorgb, (img_size,img_size))\n",
    "          training_Data.append([new_array,class_num])\n",
    "      except Exception as e:\n",
    "          pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6d9c48bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_training_Data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "66cf1039",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "random.shuffle(training_Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d27e9d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "y = []\n",
    "\n",
    "for features.label in training_Data:\n",
    "    X.append(features)\n",
    "    y.append(label)\n",
    "\n",
    "\n",
    "X = X = np.array(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "df111273",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X/255.0;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d5956ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7dd08646",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle_out = open(\"X.pickle\",\"wb\")\n",
    "pickle.dump(X, pickle_out)\n",
    "pickle_out.close()\n",
    "\n",
    "pickle_out = open(\"y.pickle\",\"wb\")\n",
    "pickle.dump(y, pickle_out)\n",
    "pickle_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "06a587f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2f905c56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet/mobilenet_1_0_224_tf.h5\n",
      "17225924/17225924 [==============================] - 3s 0us/step\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.applications.mobilenet.MobileNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "18aa812c",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_input = model.layers[0].input ## input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3f27db7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_output = model.layers[-4].output ## output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "da0342af",
   "metadata": {},
   "outputs": [],
   "source": [
    "Flat_layer = layers.Flatten()(base_output)\n",
    "final_output = layers.Dense(1)(Flat_layer) ## one node (1/0)\n",
    "final_output = layers.Activation('sigmoid')(final_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "84ce4287",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model = keras.Model(inputs = base_input, outputs= final_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1c8f947f",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model.compile(loss=\"binary_crossentropy\", optimizer = \"adam\", metrics = [\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b287b8a5",
   "metadata": {},
   "outputs": [],
   "source": [
    " new_model.fit(X,Y, epochs = 1,validation_split = 0.1)## training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0ec1b892",
   "metadata": {},
   "outputs": [],
   "source": [
    "faceCascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f9906dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "eye_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_eye.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9552dba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57fe3067",
   "metadata": {},
   "outputs": [],
   "source": [
    "eyes = eye_cascade.detectMultiScale(gray,1.1,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f50a5006",
   "metadata": {},
   "outputs": [],
   "source": [
    "for(x,y,w,h) in eyes:\n",
    "  cv2.rectangle(img,(x,y),(x+w,y+h),(0,255,0),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ef27f9b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Realtime Video Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a4cb2fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "path = \"haarcascade_frontalface_default.xml\"\n",
    "faceCascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "\n",
    "cap = cv2.VideoCapture(1)\n",
    "## Checking if the webcam is opened correctly\n",
    "if not cap.isOpened():\n",
    "  cap = cv2.VideoCapture(0)\n",
    "if not cap.isOpened():\n",
    "  raise IOError(\"Cannot open webcam\")\n",
    "\n",
    "while True:\n",
    "    ret,frame = cap.read()\n",
    "    eye_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_eye.xml')\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    #print(faceCascade.empty())\n",
    "    eyes = eye_cascade.detectMultiScale(gray,1.1,4)\n",
    "    for x,y,w,h in eyes:\n",
    "        roi_gray = gray[y:y+h, x:x+w]\n",
    "        roi_color = frame[y:y+h, x:x+w]\n",
    "        cv2.rectangle(frame, (x,y), (x+w,y+h),(0,255,0),2)\n",
    "        eyess =  eye.cascade.detectMultiScale(roi_gray)\n",
    "        if len(eyess) == 0:\n",
    "            print(\"eyes are not detected\")\n",
    "        else:\n",
    "            for (ex,ey,ew,eh) in eyess:\n",
    "                eyes_roi = roi_color[ey: ey+eh, ex:ex + ew]\n",
    "\n",
    "        final_image = cv2.resize(eyes_roi,(224,224))\n",
    "        final_image = np.expand_dims(final_image,axis =0)\n",
    "        final_image = final_image/255.0\n",
    "\n",
    "        Predictions = new_model.predict(final_image)\n",
    "        if(Predictions>0):\n",
    "            status = \"Open Eyes\"\n",
    "        else:\n",
    "            status = \"Closed Eyes\"\n",
    "\n",
    "\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        print(faceCascade.empty())\n",
    "        faces = faceCascade.detectMultiScale(gray,1.1,4)\n",
    "\n",
    "        ## Draw a rectangle around the faces\n",
    "        for(x,y,w,h) in faces:\n",
    "            cv2.rectangle(frame, (x,y),(x+w,y+h),(0,255,0),2)\n",
    "        font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "\n",
    "        ## Using putText() method for inserting text on video\n",
    "\n",
    "        cv2.putText(frame,status,(50,50),font,3,(0,0,255),2,cv2.LINE_4)\n",
    "        cv2.imshow('Drowsiness Detection',frame)\n",
    "\n",
    "        if cv2.waitKey(2) &  0xFF == odd('q'):\n",
    "          break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fd3d88a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
